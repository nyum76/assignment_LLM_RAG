{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 사용환경 준비\n",
    "### 1.1 필요 라이브러리 설치\n",
    "`pip install python-dotenv langchain langchain-openai faiss-cpu pypdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".env 파일에 OPENAI_API_KEY 를 지정해 준 뒤 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-proj-l8wPUQs3PxMzl9psPzXWSlFXgiNAfQGtTOFaQj2FGzQNZS4KlKT6c18eHs2lp8gS8-Mp-dBbgkT3BlbkFJuA9b79_enpgtDcllStNzkCoBqRoCGlkNx7LLzH4-nsu5yw0-D8vhI6qTJQTNz25dYDXrNzekYA\n"
     ]
    }
   ],
   "source": [
    "from dotenv import (\n",
    "    load_dotenv,\n",
    ")  # dotenv 모듈 : .env 파일을 읽고 여기서 정의된 환경 변수를 시스템의 환경변수로 설정함\n",
    "import os\n",
    "\n",
    "load_dotenv()  # .env 파일에서 환경 변수 로드\n",
    "\n",
    "api_key = os.getenv(\n",
    "    \"OPENAI_API_KEY\"\n",
    ")  # 환경변수에서 OPENAI_API_KEY 의 값 가져와 api_key 변수에 저장\n",
    "print(api_key)  # API KEY 가 제대로 입력됐는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    ")  # Messages 작성(사용자의 요구사항이나 질문)을 위한 모듈 import\n",
    "\n",
    "# 모델 초기화\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 문서 로드하기\n",
    "`pip install pypdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyPDFLoader : PDF 파일을 로드하고, 이를 문서로 변환. 이 문서들은 후속 작업에서 사용할 수 있도록 텍스트로 변환됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 특집원고  초거대 언어모델 연구 동향\n",
      "초거대 언어모델 연구 동향\n",
      "업스테이지  박찬준*･이원성･김윤기･김지후･이활석\n",
      " \n",
      "1. 서  론1)\n",
      "ChatGPT1)와 같은 초거대 언어모델(Large Language \n",
      "Model, LLM) 의 등장으로 기존에 병렬적으로 연구되\n",
      "던 다양한 자연언어처리 하위 분야들이 하나의 모델\n",
      "로 처리되고 있으며, 태스크 수렴 현상 (Converge)이 \n",
      "발생하고 있다. 즉 하나의 LLM으로 번역, 요약, 질의\n",
      "응답, 형태소분석 등의 작업을 모두 처리할 수 있게 \n",
      "되었다. 프롬프트 (Prompt)를 어떻게 모델에게 입력하\n",
      "느냐에 따라서 LLM의 다양한 능력들이 창발되고, 이\n",
      "에 따라 사용자의 목적에 맞는 출력을 생성하는 패러\n",
      "다임을 맞이하게 되었다 [1].\n",
      "LLM은 최근 몇 년 간의 연구 동향에 따라 뛰어난 \n",
      "발전을 이루고 있다. 이러한 발전은 몇 가지 주요한 \n",
      "요인에 기반하고 있으며, 이 요인들은 현대 자연언어\n",
      "처리 (Natural Language Processing, NLP) 연구의 핵심\n",
      "적인 추세로 간주된다. 첫째로, 데이터의 양적 확대는 \n",
      "무시할 수 없는 중요한 요인이다. 디지털화의 선도로, \n",
      "텍스트 데이터의 양이 기하급수적으로 증가하였고, \n",
      "이는 연구의 질적 변화를 가져왔다. 대규모 코퍼스의 \n",
      "활용은 LLM의 일반화 능력을 향상시키며, 다양한 맥\n",
      "락과 주제에 대한 깊은 학습을 가능하게 한다. 둘째\n",
      "로, 컴퓨팅 기술의 진보는 LLM의 발전에 있어 결정\n",
      "적이었다. 특히, Graphics Processing Unit (GPU) 및 \n",
      "Tensor Processing Unit (TPU) 와 같은 고성능 병렬 처\n",
      "리 하드웨어의 개발은 모델 학습에 있어 병목 현상을 \n",
      "크게 완화시켰다. 이로 인해 연구자들은 모델의 복잡\n",
      "성을 키우고, 더욱 깊은 신경망 구조를 탐구할 수 있\n",
      "게 되었다. 셋째, 알고리즘 및 기술의 발전은 LLM의 \n",
      "성능 향상을 주도하였다. Attention 및 Transformer \n",
      "Architecture의 도입은 연구자들에게 문맥 간의 관계\n",
      "를 더욱 정교하게 모델링할 수 있는 방법을 제공하였\n",
      "다 [2, 3]. 이 모든 변화의 중심에는 ‘scaling law’라는 \n",
      "* 정회원\n",
      "1) https://openai.com/blog/chatgpt\n",
      "학문적인 통찰이 있다 [4]. 해당 연구에 따르면, 모델\n",
      "의 크기와 그 성능은 긍정적인 상관 관계를 보인다. \n",
      "이를 통해 연구자들은 모델의 파라미터 수를 증가시\n",
      "키면서, 이에 따른 성능 향상을 기술적 진보의 상호 \n",
      "작용에서 나온 결과이며, 이러한 추세는 앞으로도 \n",
      "NLP 연구의 주요 동력이 될 것으로 예상된다.\n",
      "연구단계를 넘어 LLM은 산업계에서도 많은 발전\n",
      "을 이루어 내고 있다. LLM 은 교육, 의료, 금융, 제조 \n",
      "등 거의 모든 산업 분야에서 광범위한 활용 가능성을 \n",
      "제시하고 있다 [5, 6, 7, 8]. 교육 분야에서는 단순한 \n",
      "정보 검색을 넘어, 개인화된 학습 경로를 추천하는 시\n",
      "스템, 과제의 자동 평가, 학생들의 복잡한 질문에 대\n",
      "한 답변 제공 등의 역할로 활용될 수 있다. 이는 교육\n",
      "의 효율성과 개인화를 동시에 추구하는 현대의 교육 \n",
      "트렌드와 맞물려 큰 효과를 발휘할 것으로 기대된다. \n",
      "의료 분야에서는 환자 데이터를 기반으로 한 초기 진\n",
      "단 도구로 활용될 뿐만 아니라, 복잡한 의료 기록 분\n",
      "석, 신약 개발에 필요한 연구 데이터 분석, 또는 최신 \n",
      "의학 연구 동향 파악 등의 다양한 역할을 수행할 수 \n",
      "있다. 이로써 의료 전문가들의 결정을 보조하고, 효율\n",
      "적인 치료 방향을 도모할 수 있게 된다. 금융 분야에\n",
      "서는 개인의 투자 성향과 시장의 동향을 분석하여 투\n",
      "자 권고를 제공하는 것 외에도, 금융 위험을 상세하게 \n",
      "분석하거나, 복잡한 금융 거래를 자동화하는 시스템\n",
      "의 핵심 구성 요소로서의 역할을 할 수 있다. 이는 금\n",
      "융 서비스의 효율과 안전성 향상에 크게 기여할 것이\n",
      "다. 제조 분야에서도 LLM은 설계 단계부터 생산, 품\n",
      "질 관리에 이르기까지의 전 과정에서 데이터 분석 및 \n",
      "최적화 도구로 활용될 수 있다. 생산 효율성 향상과 \n",
      "제품 품질 향상을 도모하며, 고객의 니즈에 더욱 민첩\n",
      "하게 대응할 수 있는 기회를 제공한다.\n",
      "그러나, 이러한 긍정적인 측면들과 더불어 LLM의 \n",
      "한계점과 위험성도 고려되어야 한다. LLM 은 학습 데\n",
      "이터의 편향성을 그대로 반영할 수 있어, 편향된 결과\n",
      "나 추천을 할 가능성이 있다 [9]. 이는 특히 중요한 의\n",
      "특집원고\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader  #\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyPDFLoader(\n",
    "    \"/Users/t2023-m0072/Desktop/assignment_LLM_RAG/RAG/PDF/초거대 언어모델 연구 동향 (1).pdf\"\n",
    ")\n",
    "\n",
    "# 페이지 별 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 로드된 문서 출력\n",
    "'''for doc in docs:\n",
    "    print(doc.page_content)'''\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 문서 청크로 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Chunk VS Token\n",
    "#### Chunk\n",
    ": 문자나 단어 등의 더 큰 의미 단위로 텍스트를 나누는 방식. 문맥적 의미를 기준으로 나눈다\n",
    "* 특징\n",
    "  * 크기 : 문자수 (characters) 나 단어수 (words) 로 정의됨\n",
    "  * 의미 단위 : 청크는 텍스트를 의미가 있는 단위로 나누는데 중점을 둠. \n",
    "    * 문장 단위\n",
    "    * 문단 단위\n",
    "    * 구문 단위 등\n",
    "\n",
    "#### Token\n",
    ": 텍스트의 기본적인 처리단위. NLP 모델에서 텍스트를 벡터화 하거나 분석하기 전에 텍스트를 나누는 가장 작은 단위. 모델이 이해할 수 있는 기본적인 단위\n",
    "* 토큰화 (Tokenization) : 텍스트를 단어, 구두점, 특수 문자 등으로 분할하는 과정\n",
    "* 특징\n",
    "  * 크기 : 고정되어 있지 않음. 단어, 하위 단어, 구두점 등 다양한 요소로 구성됨\n",
    "  * 언어 모델의 기본 단위 : GPT 같은 언어 모델은 토큰을 입력 받아 처리함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 CharacterTextSplitter\n",
    "Langchain 에서 제공하는 문서 분할 도구. 문자 단위로 텍스트를 나눔.\n",
    "### 4.1.1 CharacterTextSplitter 특징 \n",
    "* **고정된 청크 크기** : 텍스트를 동일한 크기로 나눔. 일관성 있는 처리에 유용\n",
    "* **속도** : 단순한 방식 덕분에 처리 속도가 빠르고, 대규모 데이터셋을 처리할 때 효율적\n",
    "* **단순성** : 구현이 간단. 복잡한 설정 없이 다양한 응용 프로그램에 쉽게 통합\n",
    "* 중복 오버랩 (Overlap) : 각 청크 간 겹치는 부분을 두어 텍스트를 자연스럽게 나눌 수 있음. 중복을 추가해 나눠진 청크가 더 의미 있는 단위로 나뉘어 모델이 문맥을 더 잘 이해할 수 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 parameter\n",
    "* `separator` : 텍스트를 나누는 기준을 설정\n",
    "  * 기본값 : 공백 `' '`\n",
    "* `chunk_size` : 각 분할된 청크의 최대 길이를 설정\n",
    "  * `chunk_size=100` : 각 청크가 최대 100자 까지 포함됨을 의미\n",
    "* `chunk_overlap` : 청크 간 곂치는 문자 수를 설정  -> 각 텍스트간 의미가 끊어지지 않도록 하기 위함\n",
    "  * `chunk_overlap=10` : 각 청크가 이전 청크와 최대 10자 겹침\n",
    "* `length_function` : 각 청크의 길이 계산 함수\n",
    "  * `length_function=len` : 각 청크의 길이가 문자 수로 계산됨. \n",
    "  * `length_function=lambda text: len(text.split())` : 단어 수로 텍스트 나눔\n",
    "* `is_separator_regex` : separator 가 정규표현식 인지\n",
    "  * `is_separator_regex=False`(기본값) : separator로 지정된 텍스트가 정확히 일치하는 부분에서 텍스트를 나눔\n",
    "  *  `is_separator_regex=True` : separator 에 정규 표현식을 사용할 수 있음\n",
    "     *  `separator=r'\\n+'`를 사용하면 여러 줄 바꿈이 있더라도 이를 하나의 분할 기준으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:8 특집원고  초거대 언어모델 연구 동향\n",
      "초거대 언어모델 연구 동향\n",
      "업스테이지  박찬준*･이원성･김윤기･김지후･이활석\n",
      " \n",
      "1. 서  론1)\n",
      "ChatGPT1)와 같은 초거대 언어모델(Large Language \n",
      "Model, LLM) 의 등장으로 기존에 병렬적으로 연구되\n",
      "던 다양한 자연언어처리 하위 분야들이 하나의 모델\n",
      "로 처리되고 있으며, 태스크 수렴 현상 (Converge)이 \n",
      "발생하고 있다. 즉 하나의 LLM으로 번역, 요약, 질의\n",
      "응답, 형태소분석 등의 작업을 모두 처리할 수 있게 \n",
      "되었다. 프롬프트 (Prompt)를 어떻게 모\n",
      "Chunk 2:2023. 11 정보과학회지 9\n",
      "사 결정을 위해 LLM을 활용하는 경우에 문제가 될 \n",
      "수 있다. 또한, LLM 을 악의적인 목적으로 사용하는 \n",
      "위험성도 있다 [10]. 예를 들면, 미스리딩 정보 생성이 \n",
      "나 편향된 정보 전파를 위한 도구로 활용될 수 있다. \n",
      "이 외에도 LLM의 동작 원리나 결과에 대한 설명력 \n",
      "부족, 최신 정보를 반영하는 데의 한계 등 여러 문제\n",
      "점이 있으며, 이러한 문제점들을 해결하는 것은 다가\n",
      "오는 연구의 중요한 도전 과제로 여겨진다.\n",
      "즉 편향성 (LLM은 학습 데이터에 포함된 편향을 \n",
      "반영할 수 있음), 안전\n",
      "Chunk 3:10 특집원고  초거대 언어모델 연구 동향\n",
      "치하는 정보들을 기억하지 못하는 장기 의존성 문제\n",
      "가 존재한다. 이러한 문제를 극복하기 위해, LSTM \n",
      "(Long Short-Term Memory) [14] 과 GRU (Gated \n",
      "Recurrent Unit) [15] 가 등장했다. 하지만, 이들은 모두 \n",
      "텍스트에 존재하는 단방향 문맥 정보만 활용한다는 \n",
      "한계를 지닌다.\n",
      "양방향 문맥 정보를 활용하기 위해, ELMo [16] 는 \n",
      "주어진 텍스트에 존재하는 순방향 문맥 정보와 역방\n",
      "향 문맥 정보를 함께 활용하는 양방향 학습을 제안했\n",
      "다. 이\n",
      "Chunk 4:2023. 11 정보과학회지 11\n",
      "국어를 비효율적으로 토큰화하고, 학습한 한국어 토\n",
      "큰 수가 매우 부족하다는 한계를 가진다 . 실제로, \n",
      "GPT-3 [22] 의 경우 학습된 한국어 토큰의 비율은 \n",
      "0.01697% 밖에 되지 않으며, 오픈소스 LLM인 Llama \n",
      "2 [34] 의 경우도 0.06% 밖에 되지 않는다. 이에 따라, \n",
      "한국어 사용자를 위한 한국어 LLM의 필요성이 대두\n",
      "되고 있다.\n",
      "이러한 필요성에 따라, 최근 많은 국내 기업에서 \n",
      "한국어 LLM을 자체적으로 학습하기 시작했다. Naver \n",
      "Clova4)의 HyperClov\n",
      "Chunk 5:12 특집원고  초거대 언어모델 연구 동향\n",
      "요한 역할을 한다는 연구 결과들 [41, 42] 에 의해 뒷 \n",
      "받침된다. 예를 들어, 2019 년에 발표된 T5 [43] 는 웹\n",
      "페이지만을 사전학습에 활용하였으나, 이후에 공개된 \n",
      "GPT-3 [22]는 웹페이지를 비롯한, 책 및 뉴스 데이터\n",
      "를 함께 활용하였다. 더불어, Llama-1 65B 모델 [33]\n",
      "에서는 사전학습 데이터 중 웹페이지가 차지하는 비\n",
      "중이 87%에 달하지만, 남은 13%의 데이터는 대화 데\n",
      "이터, 책 및 뉴스, 학술 데이터, 코드 데이터가 골고루 \n",
      "차지하고 있다.\n",
      "이러\n",
      "Chunk 6:2023. 11 정보과학회지 13\n",
      "4.1.3 기타 고려사항\n",
      "위에서 언급한 데이터 관련 논의 외에도, LLM 사\n",
      "전학습에는 모델의 아키텍처, 모델의 상세 설정, 목적 \n",
      "함수, 학습 환경 세팅 및 학습 테크닉 등 여러 고려사\n",
      "항이 있다. 해당 논의를 모두 다루는 것은 이 논문의 \n",
      "범위를 벗어나므로, 관심 있는 독자는 다음의 서베이 \n",
      "논문 [49]을 참고하길 바란다.\n",
      "4.2 미세조정\n",
      "사전학습이 완료된 LLM은 다양한 하위 태스크를 \n",
      "해결하기 위한 기본적인 준비가 마련된 상태라 할 수 \n",
      "있다. 그럼에도 불구하고, 최근 연구 동향에 따르면 \n",
      "Chunk 7:14 특집원고  초거대 언어모델 연구 동향\n",
      "이러한 alignment criteria 는 대부분 인간의 인식을 \n",
      "기반으로 하므로 LLM에 직접 최적화 목표로서 차용\n",
      "하기에는 어려움이 따른다. 이에, LLM을 인간의 가치\n",
      "와 일치시키기 위한 방법으로 인간의 피드백을 기반\n",
      "으로 한 강화 학습 (RLHF) [27, 69] 이 제안되었다. \n",
      "RLHF는 수집된 인간의 피드백 데이터를 활용하여 \n",
      "LLM을 미세조정하는 방법으로 상술한 alignment criteria\n",
      "를 개선하는 데 유용하다. RLHF 는 강화 학습 알고리\n",
      "즘을 사용하여 인간의 \n",
      "Chunk 8:2023. 11 정보과학회지 15\n",
      "인간의 의사결정 과정과 비슷한 측면이 있다. 마지막\n",
      "으로, ICL 은 전통적인 지도학습 방식에 비해 training- \n",
      "free learning 구조를 가지고 있으므로, 새로운 태스크 \n",
      "적응에 필요한 계산 비용을 크게 줄일 수 있으며, 확\n",
      "장 가능한 (scalable) 특성을 지닌다.\n",
      "이렇듯 유용한 ICL은 어떤 원리로 작동하는 것일\n",
      "까? 연구자들은 LLM의 대표적인 활용 패러다임으로 \n",
      "자리 잡은 ICL의 작동 원리를 규명하기 위해 다양한 \n",
      "측면에서 가설을 제안하였다. Chan et al. (202\n",
      "Chunk 9:16 특집원고  초거대 언어모델 연구 동향\n",
      "Retrieval Augmented Generation (RAG) [95, 96, 97, \n",
      "98]이라 한다.\n",
      "Other Tools L a M D A  [ 4 4 ]는 대화 애플리케이션에 \n",
      "특화된 LLM으로, 검색 모듈, 계산기 및 번역기 등의 \n",
      "외부 도구 호출 기능을 가지고 있다. WebGPT [99] 는 \n",
      "웹 브라우저와의 상호작용을 통해 검색 쿼리에 사실 \n",
      "기반의 답변과 함께 출처 정보를 제공 한다. PAL \n",
      "[100]은 Python 인터프리터를 통한 복잡한 기호 추론 \n",
      "기능을 제공하며,\n",
      "Chunk 10:2023. 11 정보과학회지 17\n",
      "의 경우도 많은 모델들이 OpenLLM Leaderboard에 참\n",
      "가하고 있으며, 특히 업스테이지가 두드러진 성과를 \n",
      "보였다. 업스테이지는 해당 리더보드에서 두 번이나 \n",
      "세계 1위의 자리를 차지한 뛰어난 성과를 보였다. 이\n",
      "로 인해 다양한 국내 기업들이 이 리더보드에서의 경\n",
      "쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\n",
      "화에 일조하였다.\n",
      "5.2 Open Ko-LLM Leaderboard\n",
      "한국어에서도 Open LLM 리더보드가 운영되고 있다. \n",
      "O p e n  K o - L L M  L e a\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",  # 분할기준 : 두 줄 바꿈을 기준으로 텍스트 나누기\n",
    "    chunk_size=100,  # 청크 크기 : 최대 100자\n",
    "    chunk_overlap=10,  # 중복 오버랩 : 각 청크가 최대 10자 겹침\n",
    "    length_function=len,  # 길이 계산 함수 : 문자 수 기준 (len())\n",
    "    is_separator_regex=False,  # 구분자가 정규 표현식인지 여부 (False : 정확히 일치하는 구분자 기준)\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 청킹된 내용 상위 10개 출력\n",
    "top_10 = splits[:10]\n",
    "# print(f\"Chunk 3:{splits[3]}\")\n",
    "for i, chunk in enumerate(top_10, 1):\n",
    "    page_content = chunk.page_content\n",
    "    print(f\"Chunk {i}:{page_content[:300]}\")\n",
    "# print(f\"splits 길이 : {len(splits)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 RecursiveCharacterTextSplitter\n",
    "내용의 **문맥을 유지**하면서 텍스트를 관리 가능한 청크로 분할 하도록 하는 청킹 방식. 대량의 텍스트를 처리할 때 유용. 관련 정보들이 서로 인접하게 유지되므로 **가독성**과 **이해도**를 높이는데 효과적.\n",
    "### 4.2.1 RecursiveCharacterTextSplitter 특징\n",
    "* **계층적 세분화** : 텍스트를 문맥에 나누어 의미가 각 청크 간에 보존됨\n",
    "* **적응형 청크 크기** : 텍스트 내용에 따라 청크 크기가 달라질 수 있음. 길이가 다른 문단이 포함된 문서에 유용\n",
    "* **문맥 보존** : 주변 텍스트를 고려해 청킹 과정 중 중요한 정보가 손실되는 것을 최소화 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:8 특집원고  초거대 언어모델 연구 동향\n",
      "초거대 언어모델 연구 동향\n",
      "업스테이지  박찬준*･이원성･김윤기･김지후･이활석\n",
      " \n",
      "1. 서  론1)\n",
      "Chunk 2:1. 서  론1)\n",
      "ChatGPT1)와 같은 초거대 언어모델(Large Language \n",
      "Model, LLM) 의 등장으로 기존에 병렬적으로 연구되\n",
      "Chunk 3:던 다양한 자연언어처리 하위 분야들이 하나의 모델\n",
      "로 처리되고 있으며, 태스크 수렴 현상 (Converge)이 \n",
      "발생하고 있다. 즉 하나의 LLM으로 번역, 요약, 질의\n",
      "Chunk 4:응답, 형태소분석 등의 작업을 모두 처리할 수 있게 \n",
      "되었다. 프롬프트 (Prompt)를 어떻게 모델에게 입력하\n",
      "느냐에 따라서 LLM의 다양한 능력들이 창발되고, 이\n",
      "Chunk 5:에 따라 사용자의 목적에 맞는 출력을 생성하는 패러\n",
      "다임을 맞이하게 되었다 [1].\n",
      "LLM은 최근 몇 년 간의 연구 동향에 따라 뛰어난\n",
      "Chunk 6:발전을 이루고 있다. 이러한 발전은 몇 가지 주요한 \n",
      "요인에 기반하고 있으며, 이 요인들은 현대 자연언어\n",
      "Chunk 7:처리 (Natural Language Processing, NLP) 연구의 핵심\n",
      "적인 추세로 간주된다. 첫째로, 데이터의 양적 확대는\n",
      "Chunk 8:무시할 수 없는 중요한 요인이다. 디지털화의 선도로, \n",
      "텍스트 데이터의 양이 기하급수적으로 증가하였고, \n",
      "이는 연구의 질적 변화를 가져왔다. 대규모 코퍼스의\n",
      "Chunk 9:활용은 LLM의 일반화 능력을 향상시키며, 다양한 맥\n",
      "락과 주제에 대한 깊은 학습을 가능하게 한다. 둘째\n",
      "로, 컴퓨팅 기술의 진보는 LLM의 발전에 있어 결정\n",
      "Chunk 10:적이었다. 특히, Graphics Processing Unit (GPU) 및 \n",
      "Tensor Processing Unit (TPU) 와 같은 고성능 병렬 처\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, # 각 청크 최대 100자 까지\n",
    "    chunk_overlap=10, # 청크간 최대 10자 중복\n",
    "    length_function=len, # 길이 계산 함수 : 문자 수 기준 (len())\n",
    "    is_separator_regex=False, # 구분자가 정규 표현식인지 여부 (False : 정확히 일치하는 구분자 기준)\n",
    ")\n",
    "\n",
    "splits = recursive_text_splitter.split_documents(docs)\n",
    "\n",
    "# 청킹된 내용의 상위 10개 출력\n",
    "top_10 = splits[:10]\n",
    "# print(f\"Chunk 3:{splits[3]}\")\n",
    "for i, chunk in enumerate(top_10, 1):\n",
    "    page_content = chunk.page_content\n",
    "    print(f\"Chunk {i}:{page_content[:300]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 벡터 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:8 특집원고  초거대 언어모델 연구 동향\n",
      "초거대 언어모델 연구 동향\n",
      "업스테이지  박찬준*･이원성･김윤기･김지후･이활석\n",
      " \n",
      "1. 서  론1)\n",
      "Chunk 2:1. 서  론1)\n",
      "ChatGPT1)와 같은 초거대 언어모델(Large Language \n",
      "Model, LLM) 의 등장으로 기존에 병렬적으로 연구되\n",
      "Chunk 3:던 다양한 자연언어처리 하위 분야들이 하나의 모델\n",
      "로 처리되고 있으며, 태스크 수렴 현상 (Converge)이 \n",
      "발생하고 있다. 즉 하나의 LLM으로 번역, 요약, 질의\n",
      "Chunk 4:응답, 형태소분석 등의 작업을 모두 처리할 수 있게 \n",
      "되었다. 프롬프트 (Prompt)를 어떻게 모델에게 입력하\n",
      "느냐에 따라서 LLM의 다양한 능력들이 창발되고, 이\n",
      "Chunk 5:에 따라 사용자의 목적에 맞는 출력을 생성하는 패러\n",
      "다임을 맞이하게 되었다 [1].\n",
      "LLM은 최근 몇 년 간의 연구 동향에 따라 뛰어난\n",
      "Chunk 6:발전을 이루고 있다. 이러한 발전은 몇 가지 주요한 \n",
      "요인에 기반하고 있으며, 이 요인들은 현대 자연언어\n",
      "Chunk 7:처리 (Natural Language Processing, NLP) 연구의 핵심\n",
      "적인 추세로 간주된다. 첫째로, 데이터의 양적 확대는\n",
      "Chunk 8:무시할 수 없는 중요한 요인이다. 디지털화의 선도로, \n",
      "텍스트 데이터의 양이 기하급수적으로 증가하였고, \n",
      "이는 연구의 질적 변화를 가져왔다. 대규모 코퍼스의\n",
      "Chunk 9:활용은 LLM의 일반화 능력을 향상시키며, 다양한 맥\n",
      "락과 주제에 대한 깊은 학습을 가능하게 한다. 둘째\n",
      "로, 컴퓨팅 기술의 진보는 LLM의 발전에 있어 결정\n",
      "Chunk 10:적이었다. 특히, Graphics Processing Unit (GPU) 및 \n",
      "Tensor Processing Unit (TPU) 와 같은 고성능 병렬 처\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 벡터 스토어 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. FAISS 를 Retriever 로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 프롬프트 템플릿 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. RAG 체인 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 챗봇 구동 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
