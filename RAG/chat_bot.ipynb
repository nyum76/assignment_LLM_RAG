{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 사용환경 준비\n",
    "### 1.1 필요 라이브러리 설치\n",
    "`pip install python-dotenv langchain langchain-openai faiss-cpu pypdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".env 파일에 OPENAI_API_KEY 를 지정해 준 뒤 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import (\n",
    "    load_dotenv,\n",
    ")  # dotenv 모듈 : .env 파일을 읽고 여기서 정의된 환경 변수를 시스템의 환경변수로 설정함\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    ")  # Messages 작성(사용자의 요구사항이나 질문)을 위한 모듈 import\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "import faiss \n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "'''from dotenv import (\n",
    "    load_dotenv,\n",
    ")  # dotenv 모듈 : .env 파일을 읽고 여기서 정의된 환경 변수를 시스템의 환경변수로 설정함\n",
    "import os\n",
    "'''\n",
    "load_dotenv()  # .env 파일에서 환경 변수 로드\n",
    "\n",
    "api_key = os.getenv(\n",
    "    \"OPENAI_API_KEY\"\n",
    ")  # 환경변수에서 OPENAI_API_KEY 의 값 가져와 api_key 변수에 저장\n",
    "print(api_key)  # API KEY 가 제대로 입력됐는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    ")  # Messages 작성(사용자의 요구사항이나 질문)을 위한 모듈 import'''\n",
    "\n",
    "# 모델 초기화\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 문서 로드하기\n",
    "`pip install pypdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyPDFLoader : PDF 파일을 로드하고, 이를 문서로 변환. 이 문서들은 후속 작업에서 사용할 수 있도록 텍스트로 변환됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024년 11월호\n"
     ]
    }
   ],
   "source": [
    "'''from langchain.document_loaders import PyPDFLoader\n",
    "'''\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyPDFLoader(\n",
    "    \"/Users/t2023-m0072/Desktop/assignment_LLM_RAG/RAG/PDF/인공지능산업최신동향_2024년11월호.pdf\"\n",
    ")\n",
    "\n",
    "# 페이지 별 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 로드된 문서 출력\n",
    "'''for doc in docs:\n",
    "    print(doc.page_content)'''\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 문서 청크로 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Chunk VS Token\n",
    "#### Chunk\n",
    ": 문자나 단어 등의 더 큰 의미 단위로 텍스트를 나누는 방식. 문맥적 의미를 기준으로 나눈다\n",
    "* 특징\n",
    "  * 크기 : 문자수 (characters) 나 단어수 (words) 로 정의됨\n",
    "  * 의미 단위 : 청크는 텍스트를 의미가 있는 단위로 나누는데 중점을 둠. \n",
    "    * 문장 단위\n",
    "    * 문단 단위\n",
    "    * 구문 단위 등\n",
    "\n",
    "#### Token\n",
    ": 텍스트의 기본적인 처리단위. NLP 모델에서 텍스트를 벡터화 하거나 분석하기 전에 텍스트를 나누는 가장 작은 단위. 모델이 이해할 수 있는 기본적인 단위\n",
    "* 토큰화 (Tokenization) : 텍스트를 단어, 구두점, 특수 문자 등으로 분할하는 과정\n",
    "* 특징\n",
    "  * 크기 : 고정되어 있지 않음. 단어, 하위 단어, 구두점 등 다양한 요소로 구성됨\n",
    "  * 언어 모델의 기본 단위 : GPT 같은 언어 모델은 토큰을 입력 받아 처리함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 CharacterTextSplitter\n",
    "Langchain 에서 제공하는 문서 분할 도구. 문자 단위로 텍스트를 나눔.\n",
    "### 4.1.1 CharacterTextSplitter 특징 \n",
    "* **고정된 청크 크기** : 텍스트를 동일한 크기로 나눔. 일관성 있는 처리에 유용\n",
    "* **속도** : 단순한 방식 덕분에 처리 속도가 빠르고, 대규모 데이터셋을 처리할 때 효율적\n",
    "* **단순성** : 구현이 간단. 복잡한 설정 없이 다양한 응용 프로그램에 쉽게 통합\n",
    "* 중복 오버랩 (Overlap) : 각 청크 간 겹치는 부분을 두어 텍스트를 자연스럽게 나눌 수 있음. 중복을 추가해 나눠진 청크가 더 의미 있는 단위로 나뉘어 모델이 문맥을 더 잘 이해할 수 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 parameter\n",
    "* `separator` : 텍스트를 나누는 기준을 설정\n",
    "  * 기본값 : 공백 `' '`\n",
    "* `chunk_size` : 각 분할된 청크의 최대 길이를 설정\n",
    "  * `chunk_size=100` : 각 청크가 최대 100자 까지 포함됨을 의미\n",
    "* `chunk_overlap` : 청크 간 곂치는 문자 수를 설정  -> 각 텍스트간 의미가 끊어지지 않도록 하기 위함\n",
    "  * `chunk_overlap=10` : 각 청크가 이전 청크와 최대 10자 겹침\n",
    "* `length_function` : 각 청크의 길이 계산 함수\n",
    "  * `length_function=len` : 각 청크의 길이가 문자 수로 계산됨. \n",
    "  * `length_function=lambda text: len(text.split())` : 단어 수로 텍스트 나눔\n",
    "* `is_separator_regex` : separator 가 정규표현식 인지\n",
    "  * `is_separator_regex=False`(기본값) : separator로 지정된 텍스트가 정확히 일치하는 부분에서 텍스트를 나눔\n",
    "  *  `is_separator_regex=True` : separator 에 정규 표현식을 사용할 수 있음\n",
    "     *  `separator=r'\\n+'`를 사용하면 여러 줄 바꿈이 있더라도 이를 하나의 분할 기준으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:2024년 11월호\n",
      "\n",
      "\n",
      "Chunk 2:2024년 11월호\n",
      "Ⅰ. 인공지능 산업 동향 브리프 1. 정책/법제    ▹ 미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석························1   ▹ 미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표·····························2   ▹ 유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간··············································3   ▹ OECD, 공공 부문의 AI 도입을 위한 G7 툴킷 \n",
      "\n",
      "\n",
      "Chunk 3:Ⅰ. 인공지능 산업 동향 브리프\n",
      "\n",
      "\n",
      "Chunk 4:1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\n",
      "1\n",
      "미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석n미국 민권위원회에 따르면 연방정부와 법 집행기관에서 얼굴인식 기술이 빠르게 도입되고 있으나 이를 관리할 지침과 감독의 부재로 민권 문제를 초래할 위험 존재n미국 민권위원회는 연방정부의 책임 있는 얼굴인식 기술 사용을 위해 운영 프로토콜 개발과 실제 사용 상황의 얼굴인식 기술 평가 및 불평등 완화, 지역사회의 의견 수렴 등을 권고\n",
      "KEY Contents\n",
      "£연방정부의 얼굴인식 기술 도입에 대한 \n",
      "\n",
      "\n",
      "Chunk 5:SPRi AI Brief |  2024-11월호\n",
      "2\n",
      "미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표n미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을 지원하기 위한 지침을 발표 n지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI 솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구  \n",
      "KEY Contents\n",
      "£백악관 예산관리국, 연방정부의 AI 조달 시 책임성을 증진하기 위한 모범 관\n",
      "\n",
      "\n",
      "Chunk 6:1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\n",
      "3\n",
      "유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간n유로폴의 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오 분석 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유n그러나 AI 도입을 위해서는 기술적 과제 해결 및 다양한 윤리적·사회적 이슈 대응이 필요하며, EU AI 법에 부합하도록 기존 AI 시스템에 대한 평가와 수정도 필요\n",
      "KEY Contents\n",
      "£유로폴, 법 집행에서 AI 기술의 윤리적이고 투명한 구현\n",
      "\n",
      "\n",
      "Chunk 7:SPRi AI Brief |  2024-11월호\n",
      "4\n",
      "OECD, 공공 부문의 AI 도입을 위한 G7 툴킷 발표nOECD는 공공 부문에서 EU 및 G7 국가들의 AI 도입 모범사례와 거버넌스 프레임워크, 정책 옵션을 토대로 공공 부문의 AI 도입을 안내하는 보고서를 발표n보고서는 공공 부문의 AI 도입 시 프로토타입부터 시작해 시범 도입을 거쳐 본격적으로 구현하는 단계별 접근방식을 권고\n",
      "KEY Contents\n",
      "£OECD, G7의 사례를 토대로 공공 부문의 AI 도입을 안내하는 지침 마련nOECD가 2024년 10월 15일 안전하고 신뢰\n",
      "\n",
      "\n",
      "Chunk 8:1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\n",
      "5\n",
      "세계경제포럼, 생성AI 시대의 거버넌스 프레임워크 제시n세계경제포럼이 글로벌 정책입안자를 대상으로 생성AI의 공익적 활용과 경제·사회적 균형 달성, 위험 완화를 위한 거버넌스 프레임워크를 제안하는 백서를 발표n백서에 따르면 정부는 기존 규제를 평가해 생성AI로 인한 규제 격차를 해소하는 한편, 다양한 이해관계자 간 지식 공유를 촉진하고 미래의 AI 발전에 대비한 규제 민첩성을 갖출 필요\n",
      "KEY Contents\n",
      "£생성AI 거버넌스, 과거-현재-미래를 아우르는 프레\n",
      "\n",
      "\n",
      "Chunk 9:SPRi AI Brief |  2024-11월호\n",
      "6\n",
      "CB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중nCB인사이츠에 따르면 2024년 3분기 AI 스타트업은 전체 벤처 투자의 31%를 유치했으며, AI 스타트업의 투자금 회수 시점은 일반 기업보다 6년 빠른 것으로 확인n그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 오픈AI와 같은 거대 기업도 비용 통제에 어려움을 겪고 있다며 상당수 AI 스타트업이 실패할 것으로 예상\n",
      "KEY Contents\n",
      "£AI 스타트업, 벤처 투자의 최우선 고려 대상\n",
      "\n",
      "\n",
      "Chunk 10:1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\n",
      "7\n",
      "메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개n메타가 동영상 생성, 개인화 동영상 제작, 동영상 편집, 오디오 생성과 같은 기능을 지원하는 ‘메타 무비 젠’을 공개하고 2025년 중 인스타그램 등 자사 플랫폼에 통합할 계획n메타 무비 젠은 인간 선호도 평가에서 런웨이의 젠 3, 오픈AI의 소라, 클링 1.5와 같은 경쟁 동영상 AI 모델보다 더 높은 점수를 기록\n",
      "KEY Contents\n",
      "£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''from langchain.text_splitter import CharacterTextSplitter\n",
    "'''\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",  # 분할기준 : 두 줄 바꿈을 기준으로 텍스트 나누기\n",
    "    chunk_size=100,  # 청크 크기 : 최대 100자\n",
    "    chunk_overlap=10,  # 중복 오버랩 : 각 청크가 최대 10자 겹침\n",
    "    length_function=len,  # 길이 계산 함수 : 문자 수 기준 (len())\n",
    "    is_separator_regex=False,  # 구분자가 정규 표현식인지 여부 (False : 정확히 일치하는 구분자 기준)\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 청킹된 내용 상위 10개 출력\n",
    "top_10 = splits[:10]\n",
    "# print(f\"Chunk 3:{splits[3]}\")\n",
    "for i, chunk in enumerate(top_10, 1):\n",
    "    page_content = chunk.page_content\n",
    "    print(f\"Chunk {i}:{page_content[:300]}\\n\\n\")\n",
    "# print(f\"splits 길이 : {len(splits)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 RecursiveCharacterTextSplitter\n",
    "내용의 **문맥을 유지**하면서 텍스트를 관리 가능한 청크로 분할 하도록 하는 청킹 방식. 대량의 텍스트를 처리할 때 유용. 관련 정보들이 서로 인접하게 유지되므로 **가독성**과 **이해도**를 높이는데 효과적.\n",
    "### 4.2.1 RecursiveCharacterTextSplitter 특징\n",
    "* **계층적 세분화** : 텍스트를 문맥에 나누어 의미가 각 청크 간에 보존됨\n",
    "* **적응형 청크 크기** : 텍스트 내용에 따라 청크 크기가 달라질 수 있음. 길이가 다른 문단이 포함된 문서에 유용\n",
    "* **문맥 보존** : 주변 텍스트를 고려해 청킹 과정 중 중요한 정보가 손실되는 것을 최소화 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:2024년 11월호\n",
      "\n",
      "\n",
      "Chunk 2:2024년 11월호\n",
      "\n",
      "\n",
      "Chunk 3:Ⅰ. 인공지능 산업 동향 브리프 1. 정책/법제    ▹ 미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석························1\n",
      "\n",
      "\n",
      "Chunk 4:▹ 미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표·····························2   ▹ 유로폴, 법 집행에서 AI의 이점과\n",
      "\n",
      "\n",
      "Chunk 5:AI의 이점과 과제를 다룬 보고서 발간··············································3   ▹ OECD, 공공 부문의 AI 도입을 위한 G7\n",
      "\n",
      "\n",
      "Chunk 6:도입을 위한 G7 툴킷 발표··························································4   ▹ 세계경제포럼, 생성AI 시대의\n",
      "\n",
      "\n",
      "Chunk 7:생성AI 시대의 거버넌스 프레임워크 제시····················································5  2. 기업/산업    ▹ CB인사이츠\n",
      "\n",
      "\n",
      "Chunk 8:▹ CB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중··············6   ▹ 메타, 동영상 생성AI 도구 ‘메타 무비 젠’\n",
      "\n",
      "\n",
      "Chunk 9:‘메타 무비 젠’ 공개···································································7   ▹ 메타, 이미지와 텍스트\n",
      "\n",
      "\n",
      "Chunk 10:이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개···························8   ▹ 앨런AI연구소, 벤치마크 평가에서 GPT-4o\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "'''\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, # 각 청크 최대 100자 까지\n",
    "    chunk_overlap=10, # 청크간 최대 10자 중복\n",
    "    length_function=len, # 길이 계산 함수 : 문자 수 기준 (len())\n",
    "    is_separator_regex=False, # 구분자가 정규 표현식인지 여부 (False : 정확히 일치하는 구분자 기준)\n",
    ")\n",
    "\n",
    "splits = recursive_text_splitter.split_documents(docs)\n",
    "\n",
    "# 청킹된 내용의 상위 10개 출력\n",
    "top_10 = splits[:10]\n",
    "# print(f\"Chunk 3:{splits[3]}\")\n",
    "for i, chunk in enumerate(top_10, 1):\n",
    "    page_content = chunk.page_content\n",
    "    print(f\"Chunk {i}:{page_content[:300]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 벡터 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from langchain_openai import OpenAIEmbeddings\n",
    "'''\n",
    "# OpenAI 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 벡터 스토어 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import faiss\n",
    "from langchain_community.vectorstores import FAISS'''\n",
    "\n",
    "\n",
    "vector_store = FAISS.from_documents(documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. FAISS 를 Retriever 로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 프롬프트 템플릿 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough'''\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the question using only the following context.\"),\n",
    "    (\"user\", \"Context: {context}\\\\n\\\\nQuestion: {question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. RAG 체인 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough'''\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the question using only the following context.\"),\n",
    "    (\"user\", \"Context: {context}\\\\n\\\\nQuestion: {question}\")\n",
    "])\n",
    "\n",
    "class DebugPassThrough(RunnablePassthrough):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args, **kwargs)\n",
    "        print(\"Debug Output:\", output)\n",
    "        return output\n",
    "# 문서 리스트를 텍스트로 변환하는 단계 추가\n",
    "class ContextToText(RunnablePassthrough):\n",
    "    def invoke(self, inputs, config=None, **kwargs):  # config 인수 추가\n",
    "        # context의 각 문서를 문자열로 결합\n",
    "        context_text = \"\\n\".join([doc.page_content for doc in inputs[\"context\"]])\n",
    "        return {\"context\": context_text, \"question\": inputs[\"question\"]}\n",
    "\n",
    "# RAG 체인에서 각 단계마다 DebugPassThrough 추가\n",
    "rag_chain_debug = {\n",
    "    \"context\": retriever,                    # 컨텍스트를 가져오는 retriever\n",
    "    \"question\": DebugPassThrough()        # 사용자 질문이 그대로 전달되는지 확인하는 passthrough\n",
    "}  | DebugPassThrough() | ContextToText()|   contextual_prompt | model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 챗봇 구동 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1024469277.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    while :\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "while : \n",
    "\tprint(\"========================\")\n",
    "\tquery = input(\"질문을 입력하세요: \")\n",
    "\tresponse = rag_chain_debug.invoke(query)\n",
    "\tprint(\"Final Response:\")\n",
    "\tprint(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
