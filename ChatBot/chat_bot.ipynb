{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 사용환경 준비\n",
    "### 1.1 필요 라이브러리 설치\n",
    "`pip install python-dotenv langchain langchain-openai faiss-cpu pypdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".env 파일에 OPENAI_API_KEY 를 지정해 준 뒤 사용함\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import (\n",
    "    load_dotenv,\n",
    ")  # dotenv 모듈 : .env 파일을 읽고 여기서 정의된 환경 변수를 시스템의 환경변수로 설정함\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI # OpanAI 의 GPT 모델 사용 \n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    ")  # Messages 작성(사용자의 요구사항이나 질문)을 위한 모듈 import\n",
    "\n",
    "# 문서 로드 , 처리\n",
    "from langchain.document_loaders import PyPDFLoader # PDF 문서 읽기 위한 모듈\n",
    "from langchain.text_splitter import CharacterTextSplitter # 청킹 방법 1\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # 청킹 방법 2\n",
    "\n",
    "# 임벡딩 생성 및 벡터 스토어\n",
    "from langchain_openai import OpenAIEmbeddings # OpenAI 를 사용해 임베딩 생성\n",
    "import faiss # 벡터 검색을 위한 라이브러리\n",
    "from langchain_community.vectorstores import FAISS # LangChain 과 FAISS 를 통합 -> 검색 가능 벡터 스토어 생성\n",
    "\n",
    "# 프롬프트 정의, 실행 모듈\n",
    "from langchain_core.prompts import ChatPromptTemplate # 프롬프트 템플릿 작성\n",
    "from langchain_core.runnables import RunnablePassthrough # 데이터를 가공하지 않고 그대로 전달시 사용\n",
    "\n",
    "# RAG 체인 구성\n",
    "from langchain.chains import LLMChain # 9 번에서 LangChain 모델과 프롬프트를 연결한 RAG 체인 구성 위해 불러옴\n",
    "from langchain.chains import RetrievalQA # Retriever 와 LLM 결합해 질문에 답하는 기능\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from dotenv import (\n",
    "    load_dotenv,\n",
    ")  # dotenv 모듈 : .env 파일을 읽고 여기서 정의된 환경 변수를 시스템의 환경변수로 설정함\n",
    "import os\n",
    "\"\"\"\n",
    "\n",
    "load_dotenv()  # .env 파일에서 환경 변수 로드\n",
    "\n",
    "api_key = os.getenv(\n",
    "    \"OPENAI_API_KEY\"\n",
    ")  # os.getenv() : 환경변수에서 OPENAI_API_KEY 의 값 가져와 api_key 변수에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 모델 로드하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    ")  # Messages 작성(사용자의 요구사항이나 질문)을 위한 모듈 import\"\"\"\n",
    "\n",
    "# 모델 초기화 - 모델 선택\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. 문서 로드하기\n",
    "`pip install pypdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyPDFLoader : PDF 파일을 로드하고, 이를 문서로 변환. 이 문서들은 후속 작업에서 사용할 수 있도록 텍스트로 변환됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\n",
      "3\n",
      "유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간n유로폴의 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오 분석 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유n그러나 AI 도입을 위해서는 기술적 과제 해결 및 다양한 윤리적·사회적 이슈 대응이 필요하며, EU AI 법에 부합하도록 기존 AI 시스템에 대한 평가와 수정도 필요\n",
      "KEY Contents\n",
      "£유로폴, 법 집행에서 AI 기술의 윤리적이고 투명한 구현을 위한 고려사항 제시nEU 사법기관 유로폴(Europol)이 2024년 9월 24일 법 집행에서 효과적 범죄 퇴치를 위한 AI의 활용 가능성을 탐색한 보고서를 발간∙보고서는 법 집행에서 AI 기술을 윤리적이고 투명하게 구현하기 위한 지침 역할을 하며, AI의 이점과 과제를 함께 다룸으로써 법 집행에서 AI 사용 시 윤리적 고려 사항에 대한 인식 제고를 추구n보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오 분석, 생체인식 시스템 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유∙법 집행기관은 AI 기반 데이터 분석을 활용해 범죄 활동에 대한 탐지와 대응 능력을 강화하고, AI 도구로 구조화되지 않은 데이터를 신속히 분석해 비상 상황의 의사결정을 위한 통찰력 확보 가능 ∙기계번역과 같은 AI 기반 도구는 여러 국가가 참여하는 조사에서 원활한 국제협력을 위해서도 필수적n그러나 법 집행에서 AI 도구의 효과적이고 책임 있는 활용을 위해 해결되어야 할 기술적 과제 및 다양한 윤리적·사회적 우려도 존재∙일례로 관할권 간 데이터 수집과 보관 관행의 차이에 따른 데이터셋의 편향으로 인해 AI 산출물의 무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요∙데이터 규모나 활용 사례의 복잡성과 관계없이 AI 도구를 효과적으로 사용하려면 다양한 데이터 규모와 운영 요구사항에 적응할 수 있는 확장성과 성능을 갖춘 AI 모델도 개발 필요∙편향, 개인정보 침해와 인권 침해와 같은 다양한 윤리적·사회적 우려도 존재하며, 이를 해소하기 위해 데이터 편향을 제거하고 공공 안전과 개인정보 간 균형을 유지하며 AI 의사 결정 과정에 대한 투명성과 책임성을 보장 필요n보고서는 2024년 8월 발효된 EU AI 법이 법 집행기관에 미칠 영향도 분석∙EU AI 법은 공공장소에서 실시간 생체인식 식별과 같은 특정 애플리케이션의 사용을 금지하고 고위험 AI 시스템에 엄격한 감독을 부과하였으나 법 집행 활동의 특수성을 고려해 일부 예외를 설정 ∙그러나 일부 예외에도 법 집행 역량 강화를 위한 AI 사용을 위해서는 기존에 도입한 AI 시스템에 대한 재평가와 수정이 필요한 만큼, 재정과 인력 측면의 상당한 부담 예상☞ 출처: Europol, AI and policing-The benefits and challenges of artificial intelligence for law enforcement, 2024.09.24.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"from langchain.document_loaders import PyPDFLoader\n",
    "\"\"\"\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyPDFLoader(\n",
    "    \"/Users/t2023-m0072/Desktop/assignment_LLM_RAG/PDF/인공지능산업최신동향_2024년11월호.pdf\"\n",
    ")\n",
    "\n",
    "# 페이지 별 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 로드된 문서 출력\n",
    "\"\"\"for doc in docs:\n",
    "    print(doc.page_content)\"\"\"\n",
    "print(docs[5].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. 문서 청크로 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Chunk VS Token\n",
    "#### Chunk\n",
    ": 문자나 단어 등의 더 큰 의미 단위로 텍스트를 나누는 방식. 문맥적 의미를 기준으로 나눈다\n",
    "* 특징\n",
    "  * 크기 : 문자수 (characters) 나 단어수 (words) 로 정의됨\n",
    "  * 의미 단위 : 청크는 텍스트를 의미가 있는 단위로 나누는데 중점을 둠. \n",
    "    * 문장 단위\n",
    "    * 문단 단위\n",
    "    * 구문 단위 등\n",
    "\n",
    "#### Token\n",
    ": 텍스트의 기본적인 처리단위. NLP 모델에서 텍스트를 벡터화 하거나 분석하기 전에 텍스트를 나누는 가장 작은 단위. 모델이 이해할 수 있는 기본적인 단위\n",
    "* 토큰화 (Tokenization) : 텍스트를 단어, 구두점, 특수 문자 등으로 분할하는 과정\n",
    "* 특징\n",
    "  * 크기 : 고정되어 있지 않음. 단어, 하위 단어, 구두점 등 다양한 요소로 구성됨\n",
    "  * 언어 모델의 기본 단위 : GPT 같은 언어 모델은 토큰을 입력 받아 처리함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.1 CharacterTextSplitter\n",
    "Langchain 에서 제공하는 문서 분할 도구. 문자 단위로 텍스트를 나눔.\n",
    "### 4.1.1 CharacterTextSplitter 특징 \n",
    "* **고정된 청크 크기** : 텍스트를 동일한 크기로 나눔. 일관성 있는 처리에 유용\n",
    "* **속도** : 단순한 방식 덕분에 처리 속도가 빠르고, 대규모 데이터셋을 처리할 때 효율적\n",
    "* **단순성** : 구현이 간단. 복잡한 설정 없이 다양한 응용 프로그램에 쉽게 통합\n",
    "* 중복 오버랩 (Overlap) : 각 청크 간 겹치는 부분을 두어 텍스트를 자연스럽게 나눌 수 있음. 중복을 추가해 나눠진 청크가 더 의미 있는 단위로 나뉘어 모델이 문맥을 더 잘 이해할 수 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.1.2 parameter\n",
    "* `separator` : 텍스트를 나누는 기준을 설정\n",
    "  * 기본값 : 공백 `' '`\n",
    "  * 줄 단위 나누기 : `\\n`\n",
    "  * 문장 단위 나누기 : `.`\n",
    "  ---\n",
    "* `chunk_size` : 각 분할된 청크의 최대 길이를 설정\n",
    "  * `chunk_size=100` : 각 청크가 최대 100자 까지 포함됨을 의미\n",
    "  * 일반적으로 512~1000 토큰\n",
    "  ---\n",
    "* `chunk_overlap` : 청크 간 곂치는 문자 수를 설정  -> 각 텍스트간 의미가 끊어지지 않도록 하기 위함\n",
    "  * `chunk_overlap=10` : 각 청크가 이전 청크와 최대 10자 겹침\n",
    "  * 보통 `chunk_size` 의 10~20% 사용\n",
    "  * 중복이 너무 크면 처리 효율 하락. 적절한 설정 필요\n",
    "  ---\n",
    "* `length_function` : 각 청크의 길이 계산 함수\n",
    "  * `length_function=len` : 각 청크의 길이가 문자 수로 계산됨. \n",
    "  * `length_function=lambda text: len(text.split())` : 단어 수로 텍스트 나눔\n",
    "  ---\n",
    "* `is_separator_regex` : separator 가 정규표현식 인지\n",
    "  * `is_separator_regex=False`(기본값) : separator로 지정된 텍스트가 정확히 일치하는 부분에서 텍스트를 나눔\n",
    "  *  `is_separator_regex=True` : separator 에 정규 표현식을 사용할 수 있음\n",
    "     *  `separator=r'\\n+'`를 사용하면 여러 줄 바꿈이 있더라도 이를 하나의 분할 기준으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:2024년 11월호\n",
      "\n",
      "\n",
      "Chunk 2:2024년 11월호\n",
      "Ⅰ. 인공지능 산업 동향 브리프 1. 정책/법제    ▹ 미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석························1   ▹ 미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표·····························2   ▹ 유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간··············································3   ▹ OECD, 공공 부문의 AI 도입을 위한 G7 툴킷 \n",
      "\n",
      "\n",
      "Chunk 3:Ⅰ. 인공지능 산업 동향 브리프\n",
      "\n",
      "\n",
      "Chunk 4:1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\n",
      "1\n",
      "미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석n미국 민권위원회에 따르면 연방정부와 법 집행기관에서 얼굴인식 기술이 빠르게 도입되고 있으나 이를 관리할 지침과 감독의 부재로 민권 문제를 초래할 위험 존재n미국 민권위원회는 연방정부의 책임 있는 얼굴인식 기술 사용을 위해 운영 프로토콜 개발과 실제 사용 상황의 얼굴인식 기술 평가 및 불평등 완화, 지역사회의 의견 수렴 등을 권고\n",
      "KEY Contents\n",
      "£연방정부의 얼굴인식 기술 도입에 대한 \n",
      "\n",
      "\n",
      "Chunk 5:SPRi AI Brief |  2024-11월호\n",
      "2\n",
      "미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표n미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을 지원하기 위한 지침을 발표 n지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI 솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구  \n",
      "KEY Contents\n",
      "£백악관 예산관리국, 연방정부의 AI 조달 시 책임성을 증진하기 위한 모범 관\n",
      "\n",
      "\n",
      "Chunk 6:1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\n",
      "3\n",
      "유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간n유로폴의 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오 분석 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유n그러나 AI 도입을 위해서는 기술적 과제 해결 및 다양한 윤리적·사회적 이슈 대응이 필요하며, EU AI 법에 부합하도록 기존 AI 시스템에 대한 평가와 수정도 필요\n",
      "KEY Contents\n",
      "£유로폴, 법 집행에서 AI 기술의 윤리적이고 투명한 구현\n",
      "\n",
      "\n",
      "Chunk 7:SPRi AI Brief |  2024-11월호\n",
      "4\n",
      "OECD, 공공 부문의 AI 도입을 위한 G7 툴킷 발표nOECD는 공공 부문에서 EU 및 G7 국가들의 AI 도입 모범사례와 거버넌스 프레임워크, 정책 옵션을 토대로 공공 부문의 AI 도입을 안내하는 보고서를 발표n보고서는 공공 부문의 AI 도입 시 프로토타입부터 시작해 시범 도입을 거쳐 본격적으로 구현하는 단계별 접근방식을 권고\n",
      "KEY Contents\n",
      "£OECD, G7의 사례를 토대로 공공 부문의 AI 도입을 안내하는 지침 마련nOECD가 2024년 10월 15일 안전하고 신뢰\n",
      "\n",
      "\n",
      "Chunk 8:1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\n",
      "5\n",
      "세계경제포럼, 생성AI 시대의 거버넌스 프레임워크 제시n세계경제포럼이 글로벌 정책입안자를 대상으로 생성AI의 공익적 활용과 경제·사회적 균형 달성, 위험 완화를 위한 거버넌스 프레임워크를 제안하는 백서를 발표n백서에 따르면 정부는 기존 규제를 평가해 생성AI로 인한 규제 격차를 해소하는 한편, 다양한 이해관계자 간 지식 공유를 촉진하고 미래의 AI 발전에 대비한 규제 민첩성을 갖출 필요\n",
      "KEY Contents\n",
      "£생성AI 거버넌스, 과거-현재-미래를 아우르는 프레\n",
      "\n",
      "\n",
      "Chunk 9:SPRi AI Brief |  2024-11월호\n",
      "6\n",
      "CB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중nCB인사이츠에 따르면 2024년 3분기 AI 스타트업은 전체 벤처 투자의 31%를 유치했으며, AI 스타트업의 투자금 회수 시점은 일반 기업보다 6년 빠른 것으로 확인n그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 오픈AI와 같은 거대 기업도 비용 통제에 어려움을 겪고 있다며 상당수 AI 스타트업이 실패할 것으로 예상\n",
      "KEY Contents\n",
      "£AI 스타트업, 벤처 투자의 최우선 고려 대상\n",
      "\n",
      "\n",
      "Chunk 10:1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\n",
      "7\n",
      "메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개n메타가 동영상 생성, 개인화 동영상 제작, 동영상 편집, 오디오 생성과 같은 기능을 지원하는 ‘메타 무비 젠’을 공개하고 2025년 중 인스타그램 등 자사 플랫폼에 통합할 계획n메타 무비 젠은 인간 선호도 평가에서 런웨이의 젠 3, 오픈AI의 소라, 클링 1.5와 같은 경쟁 동영상 AI 모델보다 더 높은 점수를 기록\n",
      "KEY Contents\n",
      "£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"from langchain.text_splitter import CharacterTextSplitter\n",
    "\"\"\"\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",  # 분할기준 : 두 줄 바꿈을 기준으로 텍스트 나누기\n",
    "    chunk_size=500,  # 청크 크기 : 최대 100자\n",
    "    chunk_overlap=50,  # 중복 오버랩 : 각 청크가 최대 10자 겹침\n",
    "    length_function=len,  # 길이 계산 함수 : 문자 수 기준 (len())\n",
    "    is_separator_regex=False,  # 구분자가 정규 표현식인지 여부 (False : 정확히 일치하는 구분자 기준)\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 청킹된 내용 상위 10개 출력\n",
    "top_10 = splits[:10]\n",
    "# print(f\"Chunk 3:{splits[3]}\")\n",
    "for i, chunk in enumerate(top_10, 1):\n",
    "    page_content = chunk.page_content\n",
    "    print(f\"Chunk {i}:{page_content[:300]}\\n\\n\")\n",
    "# print(f\"splits 길이 : {len(splits)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.2 RecursiveCharacterTextSplitter\n",
    "내용의 **문맥을 유지**하면서 텍스트를 관리 가능한 청크로 분할 하도록 하는 청킹 방식. 대량의 텍스트를 처리할 때 유용. 관련 정보들이 서로 인접하게 유지되므로 **가독성**과 **이해도**를 높이는데 효과적.\n",
    "### 4.2.1 RecursiveCharacterTextSplitter 특징\n",
    "* **계층적 세분화** : 텍스트를 문맥에 나누어 의미가 각 청크 간에 보존됨\n",
    "* **적응형 청크 크기** : 텍스트 내용에 따라 청크 크기가 달라질 수 있음. 길이가 다른 문단이 포함된 문서에 유용\n",
    "* **문맥 보존** : 주변 텍스트를 고려해 청킹 과정 중 중요한 정보가 손실되는 것을 최소화 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:2024년 11월호\n",
      "\n",
      "\n",
      "Chunk 2:2024년 11월호\n",
      "\n",
      "\n",
      "Chunk 3:Ⅰ. 인공지능 산업 동향 브리프 1. 정책/법제    ▹ 미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석························1   ▹ 미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표·····························2   ▹ 유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간··············································3   ▹ OECD, 공공 부문의 AI 도입을 위한 G7 툴킷 발표·········\n",
      "\n",
      "\n",
      "Chunk 4:31%가 AI 스타트업에 집중··············6   ▹ 메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개···································································7   ▹ 메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개···························8   ▹ 앨런AI연구소, 벤치마크 평가에서 GPT-4o 능가하는 성능의 오픈소스 LLM ‘몰모’ 공개····9   ▹ 미스트랄AI, 온디바이스용 AI 모델 ‘레 미니스\n",
      "\n",
      "\n",
      "Chunk 5:AI 관련 연구자들이 수상············································12   ▹ 미국 국무부, AI 연구에서 국제협력을 위한 ‘글로벌 AI 연구 의제’ 발표························13   ▹ 일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드 발간········································14   ▹ 구글 딥마인드, 반도체 칩 레이아웃 설계하는 AI 모델 ‘알파칩’ 발표·····························15   ▹ AI21 \n",
      "\n",
      "\n",
      "Chunk 6:2025년 중 이직 고려················································18   ▹ 가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요 ·····························19   ▹ 인디드 조사 결과, 생성AI가 인간 근로자 대체할 가능성은 희박·····································20\n",
      "\n",
      "\n",
      "Chunk 7:Ⅱ. 주요 행사  ▹NeurIPS 2024 ······················································································································21  ▹GenAI Summit Maroc 2024 ·····························································································21  ▹AI Summit Seoul 2024 ··········\n",
      "\n",
      "\n",
      "Chunk 8:Ⅰ. 인공지능 산업 동향 브리프\n",
      "\n",
      "\n",
      "Chunk 9:1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\n",
      "1\n",
      "미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석n미국 민권위원회에 따르면 연방정부와 법 집행기관에서 얼굴인식 기술이 빠르게 도입되고 있으나 이를 관리할 지침과 감독의 부재로 민권 문제를 초래할 위험 존재n미국 민권위원회는 연방정부의 책임 있는 얼굴인식 기술 사용을 위해 운영 프로토콜 개발과 실제 사용 상황의 얼굴인식 기술 평가 및 불평등 완화, 지역사회의 의견 수렴 등을 권고\n",
      "KEY Contents\n",
      "\n",
      "\n",
      "Chunk 10:£연방정부의 얼굴인식 기술 도입에 대한 지침과 감독 부재로 민권 문제를 초래할 위험 존재n미국 민권위원회(U.S. Commission on Civil Rights)가 2024년 9월 19일 연방정부의 얼굴인식 기술 사용이 민권에 미치는 영향을 분석한 보고서를 발간∙AI 기술의 일종인 얼굴인식 기술은 연방정부와 법 집행기관에서 빠르게 도입되고 있으며, 일례로 법무부 연방수사국(FBI)은 범죄 수사 및 용의자 수색용 단서 확보를 위해 얼굴인식 기술을 가장 빈번히 사용∙그러나 얼굴인식 기술의 책임 있는 사용을 위한 연방 지침과 감독은 실\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\"\"\"\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # 각 청크 최대 100자 까지\n",
    "    chunk_overlap=15,  # 청크간 최대 10자 중복\n",
    "    length_function=len,  # 길이 계산 함수 : 문자 수 기준 (len())\n",
    "    is_separator_regex=False,  # 구분자가 정규 표현식인지 여부 (False : 정확히 일치하는 구분자 기준)\n",
    ")\n",
    "\n",
    "splits = recursive_text_splitter.split_documents(docs)\n",
    "\n",
    "# 청킹된 내용의 상위 10개 출력\n",
    "top_10 = splits[:10]\n",
    "# print(f\"Chunk 3:{splits[3]}\")\n",
    "for i, chunk in enumerate(top_10, 1):\n",
    "    page_content = chunk.page_content\n",
    "    print(f\"Chunk {i}:{page_content[:300]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. 벡터 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from langchain_openai import OpenAIEmbeddings\n",
    "\"\"\"\n",
    "\n",
    "# OpenAI 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. 벡터 스토어 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAISS \n",
    "(Facebook AI Similarity Search)\n",
    "* Vector DB \n",
    "* `FAISS.from_documents()` : 문서 집합을 벡터화하여 벡터 스토어(검색 가능한 Vector DB) 생성 \n",
    "* `.from_documents()` : 문서들의 집합을 받아서 해당 문서들을 벡터로 변환. 변환된 벡터를 FAISS 인덱스로 저장\n",
    "  * `documents` : 문서들 \n",
    "  * `embedding` : 임베딩 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import faiss\n",
    "from langchain_community.vectorstores import FAISS\"\"\"\n",
    "# 4.2 에서 RecursiveCharacterTextSplitter 로 청킹 했던 문서 (splits) 를 5에서 생성한 OpenAI 의 임베딩 모델을 사용해 벡터로 변환 후 저장\n",
    "vector_store = FAISS.from_documents(documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. FAISS 를 Retriever 로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retriever \n",
    "* 유사도 기반 검색을 수행\n",
    "* 벡터 스토어에서 문서를 검색하려면 이와 같은 객체가 필요함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
    "# search_kwargs={\"k\":1} : 검색할 결과의 개수로, 가장 유사한 문서 1개 검색"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. 프롬프트 템플릿 정의\n",
    "\n",
    "**필수과제를 도전과제로 대체하면서 주석처리 하였음!**\n",
    "\n",
    "순서대로\n",
    "\n",
    "- 필수과제 코드 (주석처리)\n",
    "- 도전과제 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 프롬프트 템플릿 정의\\ncontextual_prompt = ChatPromptTemplate.from_messages(   # .from_messages() : 메시지의 리스트를 기반으로 템플릿 생성\\n    [\\n        (\\n            \"system\", # 시스템 메시지로 모델의 행동 설정\\n            \"\"\"You are an assistant for question-answering tasks.\\n            Use the following pieces of retrieved context to answer the question.\\n            If you don\\'t know the answer, just say that you don\\'t know.\\n            Answer in Korean.\"\"\",\\n        ),\\n        (\"user\", \"Context: {context}\\\\n\\\\nQuestion: {question}\"), # 사용자 메시지로 모델에게 주어질 정보를 제공\\n    ] # {context} : 실제 문맥이 들어감, {question} : 사용자가 던진 질문이 들어감\\n)'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\"\"\"\n",
    "\n",
    "'''# 프롬프트 템플릿 정의\n",
    "contextual_prompt = ChatPromptTemplate.from_messages(   # .from_messages() : 메시지의 리스트를 기반으로 템플릿 생성\n",
    "    [\n",
    "        (\n",
    "            \"system\", # 시스템 메시지로 모델의 행동 설정\n",
    "            \"\"\"You are an assistant for question-answering tasks.\n",
    "            Use the following pieces of retrieved context to answer the question.\n",
    "            If you don't know the answer, just say that you don't know.\n",
    "            Answer in Korean.\"\"\",\n",
    "        ),\n",
    "        (\"user\", \"Context: {context}\\\\n\\\\nQuestion: {question}\"), # 사용자 메시지로 모델에게 주어질 정보를 제공\n",
    "    ] # {context} : 실제 문맥이 들어감, {question} : 사용자가 던진 질문이 들어감\n",
    ")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도전과제를 위한 프롬프트 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "적용 가능한 프롬프트 이름:\n",
      " - prompt1\n",
      " - prompt2\n",
      " - prompt3\n"
     ]
    }
   ],
   "source": [
    "# Prompts 폴더 내 프롬프트 파일 경로\n",
    "PROMPT_FILES = {\n",
    "    \"prompt1\": \"/Users/t2023-m0072/Desktop/assignment_LLM_RAG/Prompts/prompts1.txt\",\n",
    "    \"prompt2\": \"/Users/t2023-m0072/Desktop/assignment_LLM_RAG/Prompts/prompts2.txt\",\n",
    "    \"prompt3\": \"/Users/t2023-m0072/Desktop/assignment_LLM_RAG/Prompts/prompts3.txt\",\n",
    "}\n",
    "\n",
    "def load_prompt(file_path):\n",
    "    \"\"\"\n",
    "    주어진 파일 경로에서 프롬프트 텍스트를 읽어오는 함수.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Prompt file not found: {file_path}\")\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        prompt_text = f.read()\n",
    "    return prompt_text\n",
    "\n",
    "\n",
    "# 프롬프트를 선택하여 로드\n",
    "def select_prompt():\n",
    "    print(\"적용 가능한 프롬프트 이름:\")\n",
    "    for key in PROMPT_FILES.keys():\n",
    "        print(f\" - {key}\")\n",
    "    selected = input(\"프롬프트를 선택하세요 (예시 : prompt1): \").strip()\n",
    "    if selected not in PROMPT_FILES:\n",
    "        print(\"Invalid prompt selection. Using default: 'prompt1'\")\n",
    "        selected = \"prompt1\"\n",
    "    return selected, load_prompt(PROMPT_FILES[selected])\n",
    "\n",
    "# 프롬프트 로드 및 정의\n",
    "selected_prompt_name, prompt_text = select_prompt()\n",
    "\n",
    "# ChatPromptTemplate 생성\n",
    "contextual_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            prompt_text,  # 파일에서 로드한 프롬프트 적용\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Context: {context}\\\\n\\\\nQuestion: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. RAG 체인 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from langchain.chains import LLMChain\n",
    "'''\n",
    "# 입력값 그대로 반환하는 클래스 정의\n",
    "class SimplePassThrough:  \n",
    "    def invoke(self, inputs, **kwargs):\n",
    "        return inputs\n",
    "        \n",
    "# llm_chain 설정\n",
    "llm_chain = LLMChain(llm=model, prompt=contextual_prompt)\n",
    "# llm=model : 사용할 언어 모델 지정 ('gpt-4o-mini')\n",
    "# prompt : 사용할 프롬프트 템플릿 지정\n",
    "\n",
    "\n",
    "# 문서 내용을 프롬프트 템플릿에 맞게 변환하는 역할하는 클래스 정의\n",
    "class ContextToPrompt: \n",
    "    def __init__(self, prompt_template): # 클래스 인스턴스 생성시 사용될 프롬프트 템플릿 전달 받음\n",
    "        self.prompt_template = prompt_template\n",
    "\n",
    "    def invoke(self, inputs): \n",
    "        # 문서 내용을 텍스트로 변환\n",
    "        if isinstance(inputs, list):\n",
    "            context_text = \"\\n\".join([doc.page_content for doc in inputs]) \n",
    "        else:\n",
    "            context_text = inputs\n",
    "\n",
    "        # 프롬프트 템플릿에 적용\n",
    "        formatted_prompt = self.prompt_template.format_messages(\n",
    "            context=context_text, question=inputs.get(\"question\", \"\")\n",
    "        )\n",
    "        return formatted_prompt\n",
    "\n",
    "\n",
    "# Retriever를 invoke() 메서드로 래핑하는 클래스 정의 -> 문서 검색 수행\n",
    "class RetrieverWrapper:\n",
    "    def __init__(self, retriever): # retriever : 문서 검색 수행 객체\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def invoke(self, inputs): \n",
    "        if isinstance(inputs, dict):\n",
    "            query = inputs.get(\"question\", \"\") # inputs 에서 question 추출\n",
    "        else:\n",
    "            query = inputs\n",
    "        # 검색 수행\n",
    "        response_docs = self.retriever.get_relevant_documents(query)\n",
    "        return response_docs\n",
    "\n",
    "\n",
    "# RAG 체인 설정\n",
    "rag_chain_debug = {\n",
    "    \"context\": RetrieverWrapper(retriever), # 검색된 문서들 가져옴. retriever (실제 검색 작업 수행)\n",
    "    \"prompt\": ContextToPrompt(contextual_prompt), # 문서 내용을 프롬프트 템플릿에 맞게 변환\n",
    "    \"llm\": model, # 언어 모델 설정\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. 챗봇 구동 확인\n",
    "**필수과제를 도전과제코드로 대체 (필수과제 수행했던 부분은 주석처리함)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'while True:\\n    print(\"-------------------------------------\")\\n    query = input(\"질문을 입력하세요 (\\'exit\\' 입력시 종료) >\")\\n    print(\"질문 >\")\\n    print(query)\\n    # 종료 조건 확인 (exit 입력 시 종료)\\n    if query.lower() == \"exit\":  # .lower() 메서드 사용\\n        print(\"챗봇을 종료합니다!\")\\n        break\\n\\n    # Step 1: \\'context\\'에서 답변을 받아오기\\n    # \\'context\\'가 RunnableSequence라면 invoke()를 사용하여 결과를 받아옴\\n    response_context = rag_chain_debug[\"context\"].invoke({\"question\": query})\\n\\n    # Step 2: prompt를 생성하는 단계\\n    # \\'prompt\\'가 RunnableSequence라면 invoke()를 사용하여 결과를 받아옴\\n    prompt_msg = rag_chain_debug[\"prompt\"].invoke(\\n        {\"context\": response_context, \"question\": query}\\n    )\\n\\n    # Step 3: LLM을 이용하여 답변 생성\\n    # \\'llm\\'이 RunnableSequence라면 invoke()를 사용하여 최종 답변을 생성\\n    response_llm = rag_chain_debug[\"llm\"].invoke(prompt_msg)  # .invoke() 사용\\n\\n    # Step 4: 답변 출력\\n    print(\"\\n답변 >\")\\n    print(\\n        response_llm.content\\n    )  # 또는 response_llm.content, 정확한 속성은 모델에 따라 다름\\n\\n    try:\\n        response_context = rag_chain_debug[\"context\"].invoke({\"question\": query})\\n    except Exception as e:\\n        print(f\"Error in context invocation: {e}\")\\n        continue  # 오류가 발생하면 다시 질문을 받도록 함'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''while True:\n",
    "    print(\"-------------------------------------\")\n",
    "    query = input(\"질문을 입력하세요 ('exit' 입력시 종료) >\")\n",
    "    print(\"질문 >\")\n",
    "    print(query)\n",
    "    # 종료 조건 확인 (exit 입력 시 종료)\n",
    "    if query.lower() == \"exit\":  # .lower() 메서드 사용\n",
    "        print(\"챗봇을 종료합니다!\")\n",
    "        break\n",
    "\n",
    "    # Step 1: 'context'에서 답변을 받아오기\n",
    "    # 'context'가 RunnableSequence라면 invoke()를 사용하여 결과를 받아옴\n",
    "    response_context = rag_chain_debug[\"context\"].invoke({\"question\": query})\n",
    "\n",
    "    # Step 2: prompt를 생성하는 단계\n",
    "    # 'prompt'가 RunnableSequence라면 invoke()를 사용하여 결과를 받아옴\n",
    "    prompt_msg = rag_chain_debug[\"prompt\"].invoke(\n",
    "        {\"context\": response_context, \"question\": query}\n",
    "    )\n",
    "\n",
    "    # Step 3: LLM을 이용하여 답변 생성\n",
    "    # 'llm'이 RunnableSequence라면 invoke()를 사용하여 최종 답변을 생성\n",
    "    response_llm = rag_chain_debug[\"llm\"].invoke(prompt_msg)  # .invoke() 사용\n",
    "\n",
    "    # Step 4: 답변 출력\n",
    "    print(\"\\n답변 >\")\n",
    "    print(\n",
    "        response_llm.content\n",
    "    )  # 또는 response_llm.content, 정확한 속성은 모델에 따라 다름\n",
    "\n",
    "    try:\n",
    "        response_context = rag_chain_debug[\"context\"].invoke({\"question\": query})\n",
    "    except Exception as e:\n",
    "        print(f\"Error in context invocation: {e}\")\n",
    "        continue  # 오류가 발생하면 다시 질문을 받도록 함'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도전과제를 위한 코드 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "질문 >\n",
      " 앨런연구소에 대해 설명해줘\n",
      "\n",
      "답변 >\n",
      "앨런연구소에 대한 구체적인 정보는 제공되지 않았습니다.\n",
      "\n",
      "하지만, 앨런연구소는 인공지능 및 머신러닝 분야에서 연구와 개발을 진행하는 기관으로 알려져 있습니다.\n",
      "\n",
      "연구소의 주요 활동이나 프로젝트에 대한 정보는 공식 홈페이지나 관련 자료를 통해 확인할 수 있습니다.\n",
      "실험 결과 저장 완료: /Users/t2023-m0072/Desktop/assignment_LLM_RAG/Results/prompt2_result_1732070114.txt\n",
      "-------------------------------------\n",
      "질문 >\n",
      " 앨런연구소에서 공개한 오픈소스 LLM을 설명해줘\n",
      "\n",
      "답변 >\n",
      "앨런AI연구소에서 공개한 오픈소스 LLM은 \"몰모\"입니다.\n",
      "\n",
      "이 모델은 총 4개 모델로 구성되어 있으며, 그 중 하나는 72B 파라미터를 가진 몰모-72B입니다.\n",
      "\n",
      "몰모는 벤치마크 평가에서 GPT-4o를 능가하는 성능을 보였으며,\n",
      "\n",
      "특히 시각적 이해 능력이 뛰어납니다.\n",
      "\n",
      "또한, 몰모는 전문가 혼합 모델과 온디바이스 모델도 포함되어 있습니다.\n",
      "실험 결과 저장 완료: /Users/t2023-m0072/Desktop/assignment_LLM_RAG/Results/prompt2_result_1732070136.txt\n",
      "-------------------------------------\n",
      "질문 >\n",
      " 몰모는 언제 공개됐어?\n",
      "\n",
      "답변 >\n",
      "몰모는 2024년 9월 25일에 공개되었습니다.\n",
      "실험 결과 저장 완료: /Users/t2023-m0072/Desktop/assignment_LLM_RAG/Results/prompt2_result_1732070155.txt\n",
      "-------------------------------------\n",
      "질문 >\n",
      " exit\n",
      "챗봇을 종료합니다!\n"
     ]
    }
   ],
   "source": [
    "def save_experiment_result(prompt_name, question, response_text):\n",
    "    \"\"\"\n",
    "    실험 결과를 timestamp와 함께 /Users/t2023-m0072/Desktop/assignment_LLM_RAG/Results 디렉토리에 저장\n",
    "    \n",
    "    Args:\n",
    "    - prompt_name (str): 사용된 프롬프트 이름\n",
    "    - response_text (str): LLM에서 생성된 응답\n",
    "    \"\"\"\n",
    "    # 결과 저장 경로 변경\n",
    "    result_dir = \"/Users/t2023-m0072/Desktop/assignment_LLM_RAG/Results\"\n",
    "    os.makedirs(result_dir, exist_ok=True)  # 디렉토리 존재 여부 확인 후 생성\n",
    "    \n",
    "    timestamp = int(time.time())  # 현재 시간의 timestamp\n",
    "    filename = f\"{prompt_name}_result_{timestamp}.txt\"  # 파일명 정의\n",
    "    file_path = os.path.join(result_dir, filename) # 파일 경로\n",
    "    \n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"질문 : {question}\\n\\n\") # 질문 기록\n",
    "        f.write(f\"답변 : {response_text}\\n\")  # 응답 텍스트 기록\n",
    "        \n",
    "    print(f\"실험 결과 저장 완료: {file_path}\")\n",
    "\n",
    "while True:\n",
    "    print(\"-------------------------------------\")\n",
    "    query = input(\"질문을 입력하세요 ('exit' 입력시 종료) > \")\n",
    "    print(\"질문 >\\n\",query)\n",
    "    \n",
    "    \n",
    "    # 종료 조건\n",
    "    if query.lower() == \"exit\":\n",
    "        print(\"챗봇을 종료합니다!\")\n",
    "        break\n",
    "\n",
    "    # Step 1: 'context'에서 답변을 받아오기\n",
    "    response_context = rag_chain_debug[\"context\"].invoke({\"question\": query})\n",
    "\n",
    "    # Step 2: prompt를 생성하는 단계\n",
    "    prompt_msg = rag_chain_debug[\"prompt\"].invoke(\n",
    "        {\"context\": response_context, \"question\": query}\n",
    "    )\n",
    "\n",
    "    # Step 3: LLM을 이용하여 답변 생성\n",
    "    response_llm = rag_chain_debug[\"llm\"].invoke(prompt_msg)  # .invoke() 사용\n",
    "\n",
    "    # Step 4: 답변 출력 및 파일로 저장\n",
    "    print(\"\\n답변 >\")\n",
    "    print(response_llm.content)\n",
    "\n",
    "    # 저장 결과 파일\n",
    "    save_experiment_result(prompt_name=selected_prompt_name, question=query, response_text=response_llm.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Chat GPT 에 같은질문을 했을 때\n",
    "### Q n A\n",
    "Q. 앨런연구소에 대해 설명해줘\n",
    "\n",
    "A. 앨런 연구소(Allen Institute for Artificial Intelligence, AI2)는 인공지능(AI) 분야의 연구와 개발을 선도하는 비영리 연구 기관입니다. 이 연구소는 마이크로소프트의 공동 창립자인 폴 앨런(Paul Allen)에 의해 2014년에 설립되었습니다. 앨런 연구소는 AI와 관련된 다양한 분야에서 혁신적인 연구를 수행하며, 특히 **자연어 처리(NLP)**와 기계 학습을 중심으로 연구를 진행하고 있습니다.\n",
    "\n",
    "주요 목적과 연구 분야\n",
    "\n",
    "...\n",
    "\n",
    "주요 프로젝트\n",
    "\n",
    "...\n",
    "\n",
    "앨런 연구소의 영향\n",
    "앨런 연구소는 AI 기술을 발전시키는 데 중요한 역할을 하고 있으며, AI와 관련된 최신 연구 결과를 공개하고 협업하는 데 중점을 둡니다. 연구소는 학술지 논문, 공개 데이터셋, 오픈소스 소프트웨어 등을 통해 연구 성과를 널리 공유하고 있으며, 이를 통해 AI 분야의 진전을 촉진하고 있습니다.\n",
    "\n",
    "폴 앨런의 비전은 AI가 사회와 인간에게 이로운 방식으로 발전하도록 이끌고, 과학적 발견을 이루는 데 기여하는 것이었습니다. 앨런 연구소는 그의 유산을 이어받아, 기술 혁신과 사회적 가치를 동시에 창출하는 목표를 가지고 활동하고 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "Q. 앨런연구소의 오픈소스 LLM에 대해 설명해줘\n",
    "\n",
    "A. 앨런 연구소(Allen Institute for Artificial Intelligence, AI2)는 최근 오픈소스 대형 언어 모델(LLM) 개발에 큰 관심을 가지고 연구를 진행하고 있습니다. 이 모델은 자연어 처리(NLP) 및 기계 학습의 최신 기술을 기반으로 하여, 다양한 연구와 산업 분야에서 활용될 수 있는 잠재력을 지니고 있습니다.\n",
    "\n",
    "AI2의 오픈소스 LLM 관련 주요 프로젝트 중 하나는 **\"Grok\"**입니다. Grok은 앨런 연구소가 개발한 대형 언어 모델로, 연구자들, 개발자들, 그리고 기업들이 보다 쉽게 접근하고 사용할 수 있도록 설계되었습니다. Grok 프로젝트는 AI의 민주화와 공정한 사용을 목표로 하며, 여러 가지 핵심 특징을 가지고 있습니다.\n",
    "\n",
    "AI2의 오픈소스 LLM - Grok\n",
    "\n",
    "...\n",
    "\n",
    "결론\n",
    "앨런 연구소의 Grok 프로젝트는 AI의 최신 연구와 기술을 실제 문제 해결에 적용할 수 있는 강력한 도구를 제공하는 중요한 시도입니다. 오픈소스 대형 언어 모델로서, Grok은 많은 분야에서 활용 가능하며, AI 기술의 발전에 중요한 기여를 할 것으로 기대됩니다. AI2는 이 프로젝트를 통해 기술의 민주화와 공정성을 지향하며, AI 분야의 연구와 혁신을 지속적으로 촉진하고 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "Q. 몰모는 언제 나왔어?\n",
    "\n",
    "A. 몰모(Mistral) 모델은 2023년 9월에 공개되었습니다. 특히 Mistral 7B라는 모델이 첫 번째 버전으로 공개되었으며, 이 모델은 7억 개의 파라미터를 가지고 있습니다. Mistral은 Mixture of Experts (MoE) 아키텍처를 사용하여, 모델의 파라미터 수가 많지만 상대적으로 더 효율적이고 빠른 연산을 제공하는 특징이 있습니다.\n",
    "\n",
    "이 모델은 앨런 연구소(Allen Institute for Artificial Intelligence, AI2)가 아닌 Mistral AI라는 스타트업에서 개발한 것이기 때문에, 종종 혼동이 있을 수 있습니다. Mistral AI는 다양한 대형 언어 모델을 개발하고 있는 회사로, Mistral 모델을 오픈소스로 공개하여 AI 연구와 개발 커뮤니티에 큰 영향을 미쳤습니다.\n",
    "\n",
    "Mistral 7B 외에도, Mistral 12B라는 더 큰 모델도 함께 발표되었습니다. 이 모델은 12억 개의 파라미터를 갖추고 있으며, 다양한 자연어 처리 작업에서 높은 성능을 보여주고 있습니다. Mistral 7B와 12B 모두 오픈소스로 제공되어 연구자들이 자유롭게 사용할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 결론\n",
    "\n",
    "### 개인과제로 만들어 본 챗봇 (RAG)\n",
    "* **특화된 응답**\n",
    "  * prompt 에서 system 메시지를 직접 설정 -> prompt engineering 으로 원하는 답 유도 가능\n",
    "  * 특정 주제에 맞춰 정확한 답변 생성 가능\n",
    "* Vector DB를 바탕으로 **최신 정보 답변**\n",
    "  * '몰모'가 언제 나왔는지 물었을 때 2024년 9월에 나왔다고 했음\n",
    "#### ChatGPT\n",
    "* 최신 정보 X\n",
    "  * '몰모' 가 언제 나왔는지 물었을 때, 2023년 9월에 공개되었다고 답함\n",
    "* 할루시네이션 문제\n",
    "  * 잘 알지 못하는 정보에 대해 존재하지 않는 정보로 답변함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
